#!/bin/bash

# Copyright 2021 Google LLC
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     https://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Deploys the SQL tables and scripts needed to collect CWVs according to the 
# standard set in https://web.dev/vitals-ga4/ as well as a cloud run function
# for alerting.

set -e # stop on error
set -u # no unset variables allowed
unalias -a # don't use the user's aliases

# the information needed to send an email, excepting the recipients.
declare -A email_info
# the values used to decide if a CWV metric is poor.
declare -A cwv_thresholds

#######################################
# Gathers all of the info we need to be able to deploy
#
# Globals:
#   gcp_project
#   gcp_region
#   ga_property
#   cwv_thresholds
#   email_info
#   alert_receivers
#
# Arguments:
#   None
#######################################
get_deployment_info() {
  gcp_project=$(gcloud config get-value project)
  read -rp "Is ${gcp_project} the correct project? (y/N) " is_correct_project
  if [[ ! $is_correct_project =~ [yY] ]]; then
    read -rp "Please enter the correct GCP project ID: " gcp_project
    gcloud config set project "${gcp_project}" ||
      { printf "Unable to change the project to %s. 
Please check your project ID and try again." "${gcp_project}" >&2; 
        exit 1; }
  fi

  read -rp "Please enter the region to deploy to (use 'list' to see a list): "\
    gcp_region
  if [[ ${gcp_region} == 'list' ]]; then
    if gcloud services enable compute; then
      gcloud compute regions list | cut -d ' ' -f 1
      read -rp "Please enter the region to deploy to: " gcp_region
    else
      gcp_region=''
      printf "Unable to enable the compute service to get list of compute zones.
Please be sure to choose the same zone every time you're asked.\n"
    fi
  fi

  read -rp 'What is the ID of your GA property? ' ga_property
  if [[ ! ${ga_property} =~ ^[0-9]+$ ]]; then
    printf 'Only GA4 properties are supported at this time. Please check your 
property ID and try again.' >&2
    exit 1
  fi

  printf "\nNow we will collect your Core Web Vitals thresholds. 
If you don't enter a value, the standard values for a good score are used.\n\n"
  read -rp 'What is your Largest Contentful Paint (LCP) threshold in milliseconds? ' \
    cwv_thresholds['GOOD_LCP']
  read -rp 'What is your Cumulative Layout Shift (CLS) threshold? ' \
    cwv_thresholds['GOOD_CLS']
  read -rp 'What is your First Input Delay (FID) threshold in milliseconds? ' \
    cwv_thresholds['GOOD_FID']
  readonly cwv_thresholds

  printf "\nNext, please enter the information used when sending the alert emails\n\n"
  read -rp 'What is the address of the SMTP server to use? '\
    email_info['EMAIL_SERVER']
  read -rp 'What username will be used to authenticate with the server? '\
   email_info['EMAIL_USER']
  read -rp 'What password will be used to authenticate with the server? '\
    email_info['EMAIL_PASS']
  read -rp 'What email address will be used as the alert email sender? '\
    email_info['EMAIL_FROM']
  readonly email_info

  read -rp 'Which email addresses should receive the alert email (comma-separated list)? '\
    alert_receivers
  readonly alert_receivers

}

#######################################
# Creates the SQL files that will be used when the scripts are deployed.
#
# Template values in the sql files are replaced with the information gathered
# in get_deployment_info(). 
#
# Globals:
#   gcp_project
#   ga_property
#
# Arguments:
#   None
#
# Outputs:
#   The deployment_files directory is created and the files in the files in sql 
#   are updated then written to the new directory.
#######################################
prepare_deployment_files() (
  if [[ -d deployment_files ]]; then
    rm -r deployment_files
  fi
  mkdir deployment_files
  
  local gcp_replace="s/<PROJECT_ID>/${gcp_project}/g" 
  local ga_replace="s/<GA_ID>/${ga_property}/g" 
  for sql_file in ./sql/*.sql; do
    sed -e "${gcp_replace}" -e "${ga_replace}" "${sql_file}" \
    > deployment_files/"$(basename "${sql_file}")";
  done
)

#######################################
# Deploy the solution parts.
#
# The bq command is used to run the sql scripts, the Cloud Run function is 
# deployed from source, and the eventarc trigger is created using the default
# service account.
#
# Globals:
#   ga_property
#   cwv_thresholds
#   email_info
#   alert_receivers
#
# Arguments:
#   None
#######################################
deploy() (
  printf "\nDeploying the SQL scripts.\n"

  gcloud services enable bigquerydatatransfer.googleapis.com ||
    { printf "Unable to enable BigQuery Data Transfer."; exit 1; }
  # bq requires the user to open a URL and paste a version_info string into the
  # console when scheduling a query. Using a redirect to pass the contents of 
  # the file with the query results in bq getting an EOF and dying. Therefore we
  # cat the file at the end. 
  bq query \
    --use_legacy_sql=false \
    --destination_table=analytics_"${ga_property}".web_vitals_summary \
    --display_name='Update Web Vitals Summary' \
    --schedule='every 24 hours' \
    --replace=true \
    "'$(cat ./deployment_files/cwv_create_materialized_tables.sql)'" ||
      { printf "Error creating scheduled query for materialized summary";
        exit 1; }

  bq query --use_legacy_sql=false < ./deployment_files/cwv_create_p75_procedure.sql

  printf "Deploying the Cloud Run alerting function.\n"
  
  # using : as a deliminator to allow commas in the alert_receivers
  local env_vars="^:^ANALYTICS_ID=${ga_property}:"
  for key in "${!cwv_thresholds[@]}"; do
    env_vars+="${key}=${cwv_thresholds[${key}]}:"
  done
  for key in "${!email_info[@]}"; do
    env_vars+="${key}=${email_info[${key}]}:"
  done
  env_vars+="ALERT_RECEIVERS=${alert_receivers}"
  
  declare -a cloud_run_flags
  cloud_run_flags=(--set-env-vars="${env_vars}" --source notifications)
  if [[ -n "${gcp_region}" ]]; then
    cloud_run_flags+=(--region="${gcp_region}")
  fi
  gcloud run deploy cwv-alerting-service "${cloud_run_flags[@]}" || 
    { printf "Error deploying to Cloud Run.\n" >&2; exit 1; }

  printf "Creating the eventarc trigger for the email alerts.\n"
  if [[ -z ${gcp_region} ]]; then
    read -rp 'Please enter the region you deployed the Cloud Run function to: ' \
      gcp_region
  fi
  local service_account
  service_account=$(gcloud iam service-accounts list | \
    grep -E -o '[0-9]+-compute@developer.gserviceaccount.com')
  gcloud eventarc triggers create cwv-alert-email-trigger \
    --destination-run-service=cwv-alerting-service \
    --location="${gcp_region}" \
    --service-account="${service_account}" \
    --event-filters="type=google.cloud.audit.log.v1.written" \
    --event-filters="serviceName=bigquery.googleapis.com" \
    --event-filters="methodName=google.cloud.bigquery.v2.JobService.InsertJob" ||
    { printf "Error creating EventArc trigger for email alerting." >&2; exit 1; }
)

#######################################
# Remove the temporary deployment files and return to the directory the script 
# was called from.
#
# Globals:
#   original_dir
# 
# Arguments:
#   None
#######################################
clean_up() (
  rm -r deployment_files
  cd "${original_dir}"
)

#######################################
# The main entry point.
#
# The current working directory is saved and then the working directory is 
# changed to that of the script. The the parts of the deployment process are 
# called in turn.
#
# Globals:
#   original_dir
#
# Arguments:
#   None
#######################################
main() (
  # save the current working dir and then cd into the script's dir
  readonly original_dir=${PWD}
  cd "$(cd -- "$(dirname -- "${BASH_SOURCE[0]}" )" && pwd)"
  get_deployment_info
  prepare_deployment_files
  deploy
  clean_up
)

main "$@"
